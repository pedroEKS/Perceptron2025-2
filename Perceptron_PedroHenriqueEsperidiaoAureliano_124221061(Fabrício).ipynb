{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHJkqfuHYSqZ0YcFUsV+4C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedroEKS/Perceptron2025-2/blob/main/Perceptron_PedroHenriqueEsperidiaoAureliano_124221061(Fabr%C3%ADcio).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Perceptron para a Porta Lógica AND**\n",
        "\n",
        "Após o treinamento, o Perceptron conseguiu classificar corretamente todas as entradas da porta lógica AND. O modelo convergiu de forma rápida e eficiente para uma solução que replica a tabela verdade esperada. Os valores finais que o modelo encontrou foram:\n",
        "\n",
        "**Pesos Finais:** `[0.14908024, 0.30142861]`\n",
        "**Viés Final:** `-0.43601211637718984`\n",
        "\n",
        "Esses valores representam a \"memória\" do Perceptron. Eles fazem com que a soma ponderada seja positiva (resultando em uma saída 1) apenas quando as duas entradas são 1.\n",
        "\n",
        "‎\n",
        "‎\n",
        "#### **Impacto da Variação dos Hiperparâmetros**\n",
        "\n",
        "Ajustar a **taxa de aprendizado** (`learning_rate`) e o número de **épocas** (`epochs`) teve um impacto significativo no processo de treinamento:\n",
        "\n",
        " **Taxa de Aprendizado (`learning_rate`):** Um valor de `0.1` se mostrou ideal. Taxas mais altas, como `1.0`, causaram oscilação e impediram que o modelo convergisse. Taxas muito baixas, como `0.01`, resultaram em um treinamento excessivamente lento.\n",
        " **Épocas (`epochs`):** O modelo convergiu em apenas 11 épocas. Isso demonstrou a eficiência do algoritmo e a importância da condição de parada, que encerra o treinamento assim que a solução é encontrada.\n",
        "\n",
        "‎\n",
        "‎\n",
        "#### **A Função de Ativação DEGRAU**\n",
        "\n",
        "A **função degrau**, que foi extraída para um método próprio, mostrou-se a escolha perfeita para este problema.\n",
        "\n",
        "Com a simplicidade e natureza binária (retornando `1` para resultados positivos e `0` para negativos) se alinha perfeitamente com a lógica discreta das portas AND e OR. O uso dessa função garante que a decisão do Perceptron seja sempre objetiva."
      ],
      "metadata": {
        "id": "uVfFNP7h7Ukb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oun16YHg3opV",
        "outputId": "a76a8226-d1dd-4add-f9f1-879c05f84494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "╭━━━╮╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╭╮╱╱╱╱╱╱╱╭━━━━╮╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╭╮\n",
            "┃╭━╮┃╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱┃┃╱╱╱╱╱╱╱┃╭╮╭╮┃╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╭╯╰╮\n",
            "┃┃╱╰╋━━┳╮╭┳━━┳━━┳━━┳━╮╭━╯┣━━╮╭━━╮╰╯┃┃┣┻┳━━┳┳━╮╭━━┳╮╭┳━━┳━╋╮╭╋━━╮\n",
            "┃┃╱╭┫╭╮┃╰╯┃┃━┫╭━┫╭╮┃╭╮┫╭╮┃╭╮┃┃╭╮┃╱╱┃┃┃╭┫┃━╋┫╭╮┫╭╮┃╰╯┃┃━┫╭╮┫┃┃╭╮┃\n",
            "┃╰━╯┃╰╯┃┃┃┃┃━┫╰━┫╭╮┃┃┃┃╰╯┃╰╯┃┃╰╯┃╱╱┃┃┃┃┃┃━┫┃┃┃┃╭╮┃┃┃┃┃━┫┃┃┃╰┫╰╯┃\n",
            "╰━━━┻━━┻┻┻┻━━┻━━┻╯╰┻╯╰┻━━┻━━╯╰━━╯╱╱╰╯╰╯╰━━┻┻╯╰┻╯╰┻┻┻┻━━┻╯╰┻━┻━━╯\n",
            "\n",
            "Nossos pesos iniciais são: [-0.25091976  0.90142861]\n",
            "O viés inicial é: 0.4639878836228102\n",
            "\n",
            "Ele aprendeu! Concluímos o treinamento em 12 épocas.\n",
            "\n",
            "\n",
            "\n",
            "╭━━━╮╭━━━━╮╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╭╮╱╱╱╱╭━━━━╮╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╭╮\n",
            "┃╭━╮┃┃╭╮╭╮┃╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╭╯╰╮╱╱╱┃╭╮╭╮┃╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱┃┃\n",
            "┃┃╱┃┃╰╯┃┃┣┻┳━━┳┳━╮╭━━┳╮╭┳━━┳━╋╮╭╋━━╮╰╯┃┃┣┻━┳━┳╮╭┳┳━╮╭━━┳╮╭┫┃\n",
            "┃┃╱┃┃╱╱┃┃┃╭┫┃━╋┫╭╮┫╭╮┃╰╯┃┃━┫╭╮┫┃┃╭╮┃╱╱┃┃┃┃━┫╭┫╰╯┣┫╭╮┫╭╮┃┃┃┣╯\n",
            "┃╰━╯┃╱╱┃┃┃┃┃┃━┫┃┃┃┃╭╮┃┃┃┃┃━┫┃┃┃╰┫╰╯┃╱╱┃┃┃┃━┫┃┃┃┃┃┃┃┃┃╰╯┃╰╯┣╮\n",
            "╰━━━╯╱╱╰╯╰╯╰━━┻┻╯╰┻╯╰┻┻┻┻━━┻╯╰┻━┻━━╯╱╱╰╯╰━━┻╯╰┻┻┻┻╯╰┻━━┻━━┻╯\n",
            "\n",
            "Os pesos que ele aprendeu foram: [0.14908024 0.30142861]\n",
            "O viés final é: -0.43601211637718984\n",
            "\n",
            "Vamos ver se ele passa no teste\n",
            "Entrada: [0 0], Resposta Esperada: 0, Resposta do Perceptron: 0\n",
            "Entrada: [0 1], Resposta Esperada: 0, Resposta do Perceptron: 0\n",
            "Entrada: [1 0], Resposta Esperada: 0, Resposta do Perceptron: 0\n",
            "Entrada: [1 1], Resposta Esperada: 1, Resposta do Perceptron: 1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "#se o resultado do cálculo for positivo (>= 0), a gente diz \"SIM\" (1). se negativo diz \"NÃO\" (0)\n",
        "def funcao_ativacao_degrau(soma_ponderada):\n",
        "    if soma_ponderada >= 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "inputs = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])\n",
        "\n",
        "# respostas certas que ele precisa\n",
        "outputs = np.array([0, 0, 0, 1])  #combinação ([1,1]) dá 1.\n",
        "\n",
        "learning_rate = 0.1 #0.1 seguro!?\n",
        "epochs = 100\n",
        "\n",
        "np.random.seed(42)  #começa um chute inicial\n",
        "weights = np.random.uniform(low=-1.0, high=1.0, size=2)\n",
        "bias = np.random.uniform(low=-1.0, high=1.0)\n",
        "\n",
        "print(\"\"\"\n",
        "\n",
        "╭━━━╮╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╭╮╱╱╱╱╱╱╱╭━━━━╮╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╭╮\n",
        "┃╭━╮┃╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱┃┃╱╱╱╱╱╱╱┃╭╮╭╮┃╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╭╯╰╮\n",
        "┃┃╱╰╋━━┳╮╭┳━━┳━━┳━━┳━╮╭━╯┣━━╮╭━━╮╰╯┃┃┣┻┳━━┳┳━╮╭━━┳╮╭┳━━┳━╋╮╭╋━━╮\n",
        "┃┃╱╭┫╭╮┃╰╯┃┃━┫╭━┫╭╮┃╭╮┫╭╮┃╭╮┃┃╭╮┃╱╱┃┃┃╭┫┃━╋┫╭╮┫╭╮┃╰╯┃┃━┫╭╮┫┃┃╭╮┃\n",
        "┃╰━╯┃╰╯┃┃┃┃┃━┫╰━┫╭╮┃┃┃┃╰╯┃╰╯┃┃╰╯┃╱╱┃┃┃┃┃┃━┫┃┃┃┃╭╮┃┃┃┃┃━┫┃┃┃╰┫╰╯┃\n",
        "╰━━━┻━━┻┻┻┻━━┻━━┻╯╰┻╯╰┻━━┻━━╯╰━━╯╱╱╰╯╰╯╰━━┻┻╯╰┻╯╰┻┻┻┻━━┻╯╰┻━┻━━╯\n",
        "\"\"\")\n",
        "print(f\"Nossos pesos iniciais são: {weights}\")\n",
        "print(f\"O viés inicial é: {bias}\\n\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_error = 0\n",
        "    # passar por cada um dos 4 cenários pra ver se ele acerta\n",
        "    for i in range(len(inputs)):\n",
        "\n",
        "        weighted_sum = np.dot(inputs[i], weights) + bias #  multiplica as entradas pelos pesos e soma o viés\n",
        "\n",
        "        prediction = funcao_ativacao_degrau(weighted_sum) #ativação\n",
        "\n",
        "        error = outputs[i] - prediction #calcula o erro!?\n",
        "\n",
        "        weights += error * inputs[i] * learning_rate # ajustar os pesos com base no erro\n",
        "        bias += error * learning_rate\n",
        "\n",
        "\n",
        "        total_error += abs(error) # soma o erro total pra saber se ele aprendeu tudo\n",
        "\n",
        "    # Se o erro total for zero = que ele acertou TUDO\n",
        "    if total_error == 0:\n",
        "        print(f\"Ele aprendeu! Concluímos o treinamento em {epoch + 1} épocas.\")\n",
        "        break\n",
        "\n",
        "print(\"\"\"\\n\n",
        "\n",
        "╭━━━╮╭━━━━╮╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╭╮╱╱╱╱╭━━━━╮╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╭╮\n",
        "┃╭━╮┃┃╭╮╭╮┃╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╭╯╰╮╱╱╱┃╭╮╭╮┃╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱╱┃┃\n",
        "┃┃╱┃┃╰╯┃┃┣┻┳━━┳┳━╮╭━━┳╮╭┳━━┳━╋╮╭╋━━╮╰╯┃┃┣┻━┳━┳╮╭┳┳━╮╭━━┳╮╭┫┃\n",
        "┃┃╱┃┃╱╱┃┃┃╭┫┃━╋┫╭╮┫╭╮┃╰╯┃┃━┫╭╮┫┃┃╭╮┃╱╱┃┃┃┃━┫╭┫╰╯┣┫╭╮┫╭╮┃┃┃┣╯\n",
        "┃╰━╯┃╱╱┃┃┃┃┃┃━┫┃┃┃┃╭╮┃┃┃┃┃━┫┃┃┃╰┫╰╯┃╱╱┃┃┃┃━┫┃┃┃┃┃┃┃┃┃╰╯┃╰╯┣╮\n",
        "╰━━━╯╱╱╰╯╰╯╰━━┻┻╯╰┻╯╰┻┻┻┻━━┻╯╰┻━┻━━╯╱╱╰╯╰━━┻╯╰┻┻┻┻╯╰┻━━┻━━┻╯\n",
        "\"\"\")\n",
        "print(f\"Os pesos que ele aprendeu foram: {weights}\")\n",
        "print(f\"O viés final é: {bias}\")\n",
        "\n",
        "print(\"\\nVamos ver se ele passa no teste\")\n",
        "for i in range(len(inputs)):\n",
        "    weighted_sum = np.dot(inputs[i], weights) + bias\n",
        "    final_prediction = funcao_ativacao_degrau(weighted_sum)\n",
        "    print(f\"Entrada: {inputs[i]}, Resposta Esperada: {outputs[i]}, Resposta do Perceptron: {final_prediction}\")"
      ]
    }
  ]
}